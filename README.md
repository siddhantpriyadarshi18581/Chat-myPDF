# ğŸ“š Research-GPT: A Retrieval-Augmented Generation (RAG) System

Research-GPT is a powerful document-based Q&A system built using **Streamlit, FAISS, and Ollama LLMs**. It allows users to query a collection of research papers (PDFs), retrieve relevant information, and get AI-generated answers in a structured and context-aware format.

## ğŸš€ Features
- ğŸ“„ **Automatic PDF Processing** â€“ Upload research papers or any text-heavy PDFs.
- ğŸ” **Intelligent Document Search** â€“ Uses **FAISS** to retrieve the most relevant chunks.
- ğŸ§  **AI-Powered Answers** â€“ Utilizes **Ollama LLMs (Llama 3.2:1B)** to generate responses.
- ğŸ¯ **Optimized for Research** â€“ Provides well-structured bullet-point answers from context only.
- ğŸ–¥ï¸ **Interactive UI with Streamlit** â€“ Simple and user-friendly web-based interface.

## ğŸ“‚ Project Structure
```
Research-GPT/
â”‚â”€â”€ rag-dataset/            # Folder containing research PDFs
â”‚â”€â”€ app.py                  # Main application script (Streamlit UI + RAG Pipeline)
â”‚â”€â”€ requirements.txt        # List of dependencies
â”‚â”€â”€ README.md               # Project documentation (this file)
```

## ğŸ› ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository
```sh
git clone https://github.com/your-repo/research-gpt.git
cd research-gpt
```

### 2ï¸âƒ£ Create a Virtual Environment
```sh
python -m venv rag
source rag/bin/activate  # For Mac/Linux
rag\Scripts\activate     # For Windows
```

### 3ï¸âƒ£ Install Dependencies
```sh
pip install -r requirements.txt
```

### 4ï¸âƒ£ Start the Ollama Server
Download and install [Ollama](https://ollama.com), then run:
```sh
ollama serve
```

### 5ï¸âƒ£ Run the Application
```sh
streamlit run app.py
```

## ğŸ—ï¸ How It Works

1ï¸âƒ£ **Load PDFs:** The system scans the `rag-dataset/` folder and extracts text.

2ï¸âƒ£ **Split Text into Chunks:** Documents are split into smaller, meaningful sections.

3ï¸âƒ£ **Embed and Index Text:** FAISS stores and indexes document embeddings for efficient retrieval.

4ï¸âƒ£ **User Queries:** When a user asks a question, the system retrieves the most relevant text chunks.

5ï¸âƒ£ **AI-Powered Answer Generation:** The retrieved chunks are passed to an **LLM (Llama 3.2:1B)** to generate a response.

6ï¸âƒ£ **Display Results:** The answer is displayed in a clean and structured format via Streamlit.

## ğŸ¯ Example Query
**User Input:** _"What is the impact of AI on cybersecurity?"_

**Response:**
âœ… AI is used in cybersecurity for:
- Threat detection and anomaly identification.
- Automated response to security incidents.
- Enhancing fraud detection using machine learning.

## âš¡ Technologies Used
- **Python** â€“ Core language for backend processing.
- **Streamlit** â€“ Interactive and user-friendly UI.
- **FAISS** â€“ Efficient similarity search for document retrieval.
- **Ollama LLMs (Llama 3.2:1B)** â€“ AI model for response generation.
- **PyMuPDF** â€“ PDF text extraction and processing.

## ğŸŒŸ Future Enhancements
- ğŸ”— **Web Scraper** â€“ Fetch real-time articles for enhanced knowledge retrieval.
- ğŸ™ï¸ **Voice Input** â€“ Allow users to speak queries.
- ğŸŒ **Multi-Language Support** â€“ Process and answer questions in various languages.

## ğŸ¤ Contributing
Want to improve Research-GPT? Feel free to fork the repository and submit pull requests! ğŸš€

## ğŸ“œ License
This project is licensed under the **MIT License**.

---
ğŸ’¡ _Built with â¤ï¸ by [Your Name]_

